{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ALGORITMO DOWNLOAD PCAP\n",
    "\n",
    "Il download è suddiviso in 5 fasi e sono il frutto di un processo di reverse engineering del processo di download della pagina contenente i pcap files (<a href='http://dataset.tlm.unavarra.es/ransomware/'>unavarra.es</a>).\n",
    "\n",
    "1. ristrutturare json estratto dal sito;\n",
    "2. download pcap files da <a href='https://www.malware-traffic-analysis.net/index.html'>malware-traffic-analysis</a>;\n",
    "3. invio POST dataset.tlm.unavarra.es/ransomware/php/descargar.php;\n",
    "4. acquisire risultato POST;\n",
    "5. download pcap files da <a href='http://dataset.tlm.unavarra.es/download/'>dataset.tlm.unavarra.es/download/</a>.\n",
    "6. Decomprimo i file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "#modulo per ricostruzione json\n",
    "import json\n",
    "#moduli per download pcap file\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "#moduli per download multi thread\n",
    "import queue\n",
    "from Downloader import Downloader\n",
    "#modulo per decompressione file zip(.zip) e gzip(.gz)\n",
    "from zipfile import ZipFile\n",
    "import shutil\n",
    "import gzip as gz"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DS_BASE_PCAP = \"/Volumes/Archivio/\"\n",
    "\n",
    "#LOG string\n",
    "LOG_FAIL = \"\\tDownload failed\"\n",
    "LOG_SUCCESS = \"\\tDownload successfully\"\n",
    "LOG_NOTEXIST = \"\\tFile non exist\"\n",
    "\n",
    "#download multi thread\n",
    "NO_WORKER = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RISTRUTTURAZIONE JSON\n",
    "\n",
    "Il file 'ransom.json' è stato estratto nel momento in cui si carica la pagina il quale contiene un elemento per ciascun sample analizzando il traffico di rete del browser con gli **strumenti da sviluppatore**.\n",
    "<br>\n",
    "<img src=\"./imgMD/response_json_php.png\" width=\"850\"/>\n",
    "<br>\n",
    "Alla fine di questo processo si vuole ottenere sempre un **json ristrutturato** con la seguente struttura in modo da raggruppare i vari sample per classe per poter replicare la struttura all'interno del file system:\n",
    "\n",
    "~~~\n",
    "{\n",
    "    \"famiglia1\":[\n",
    "        {\n",
    "        \"SamplePcap\": \"path\",\n",
    "        \"Hash\": \"file_hash\",\n",
    "        \"Link\": \"URL\",\n",
    "        \"Scenario\": \"NAT o Original\"\n",
    "        \"Family\": \"NAT o Original\"\n",
    "        },\n",
    "        {\"...\"}\n",
    "    ],\n",
    "\n",
    "    \"faliglia2\": [\"...\"],\n",
    "\n",
    "    \"...\" : [\"...\"],\n",
    "\n",
    "    \"faligliaN\": [\"...\"]\n",
    "}\n",
    "~~~\n",
    "\n",
    "* **SamplePcap**, contiene il percorso dove trovare il pcap file relativo al sample;\n",
    "* **Hash**, contiene l'hash del sample preso in esame;\n",
    "* **Link**, contiene URL dal quale è stato scaricato il binario (lo useremo per velocizzare il processo di download nel caso in cui il binario è stato scaricato da malware-traffic-analysis.net);\n",
    "* **Scenario**, indica lo scenario utilizzato per l'analisi e può prendere due possibili valori: **Original o NAT**. Nel primo si è catturato solo il traffico tra client e server, invece nel secondo è stato catturato anche il traffico tra l'utente e internet.\n",
    "<br>\n",
    "\n",
    "<p align=\"center\"><img src=\"./imgMD/scenario.png\" width=\"850\" align=center></p>\n",
    "<p align=\"center\">http://dataset.tlm.unavarra.es/ransomware/scenario_moreInfo_ioOps.html</p>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def serialize_json(filename, data):\n",
    "    with open(f\"{filename}\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "        f.close()\n",
    "    print(f\"Data serialized to path: {filename}\")\n",
    "\n",
    "def read_json(path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf8\") as file:\n",
    "            data = json.load(file)\n",
    "        print(f\"Data read from path: {path}\")\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"No data found at path: {path}\")\n",
    "        return {}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: ransom.json\n",
      "Data serialized to path: ransom_restructured.json\n"
     ]
    }
   ],
   "source": [
    "samples = \"ransom.json\"\n",
    "samples_dict = read_json(samples)\n",
    "samples_restructured = {}\n",
    "\n",
    "for i in range(len(samples_dict)):\n",
    "    family = samples_dict[str(i)][0]['Family']\n",
    "\n",
    "    if family not in samples_restructured.keys():\n",
    "        samples_restructured[family] = []\n",
    "\n",
    "    sample = {\n",
    "        \"SamplePcap\" : samples_dict[str(i)][0]['SamplePcap'],\n",
    "        \"Hash\" : samples_dict[str(i)][0]['Hash'],\n",
    "        \"Link\" : samples_dict[str(i)][0]['Link'],\n",
    "        \"Scenario\" : samples_dict[str(i)][0]['Scenario'],\n",
    "        \"Family\" : family\n",
    "    }\n",
    "\n",
    "    samples_restructured[family].append(sample)\n",
    "\n",
    "serialize_json('ransom_restructured.json', samples_restructured)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DOWNLOAD PCAP FILES\n",
    "\n",
    "In questa fase posso trovarmi in 2 possibbili scenari che variano a seconda della sorgente del file binario. La prima possibilità è che sia stato scaricato da <a href=\"https://www.malware-traffic-analysis.net/index.html\">malware-traffic-analysis.net</a> (da ora lo abbreviamo che MTA), la seconda è <a href=\"https://www.hybrid-analysis.com/\">hybrid-analysis.com</a> (abbreviamo con HA). Per velocizzare il processo di download nel primo caso andiamo a scaricare direttamente i pcap da MTA, invece nel secondo andiamo a scaricare i pcap da <a href=\"http://dataset.tlm.unavarra.es/ransomware/\">univarra.es</a> eseguendo i seguenti passaggi:\n",
    "\n",
    "1. invio POST a *dataset.tlm.unavarra.es/ransomware/php/descargar.php* con il seguente payload contenente:\n",
    "   * *tokenDescarga=*;\n",
    "   * *descargarTodo=0*;\n",
    "   * il valore di *sample* varia in base allo scenario in cui mi trovo.\n",
    "2. acquisire la response della POST al *passo 1* in formato. Un esempio di response:\n",
    "    ~~~\n",
    "    {\"name\":\"..\\/downloads\\/39e735642167b365b9546bf9e7cd27d5eb532f75.pcap.gz\"}\n",
    "    ~~~\n",
    "   <br>\n",
    "   La sequesnza di caratteri ha lunhezza fissa (40 caratteri), quidi è sicurante il risultato di una hash. Tale stringa però, a parità di valori degli attributi ad ogni esecuzione il risultato della funzione di hash cambia e ciò vuol dire che realizza un hash aggiungendo una stringa che cambia sempre (esegue salting, concatena un timestamp, ...).\n",
    "3. download risorsa (GET) all'indirizzo *dataset.tlm.unavarra.es/download/?*, dove al posto della wildcard (?) ci va il file indicato dalla POST al *passo 2*."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DOWNLOA PCAP FILES DA MALWARE-TRAFFIC-ANALYSIS.NET\n",
    "\n",
    "Il link per il download della risorsa viene reperito attraverso uno scrapping della pagina web. Dall' analisi dell'html si è notato che il link alla risorsa è un item di una lista presente sia all'inizio e sia alla fine della pagina (per comodità prendiamo la lista iniziale) ed è sempre il primo elemento della lista applicando il seguente filtro: **ul>li** oppure possiamo usare lal classe *menu_link*.\n",
    "<br>\n",
    "Qui di seguito il pezzo di html del sito a cui facciamo riferimento\n",
    "\n",
    "~~~\n",
    "<ul>\n",
    "    <li>\n",
    "        ZIP archive of the pcap:&nbsp;\n",
    "        <a class=\"menu_link\" href=\"2016-12-11-pseudoDarkleech-Rig-V-sends-Cerber-ransomware.pcap.zip\">2016-12-11-pseudoDarkleech-Rig-V-sends-Cerber-ransomware.pcap.zip</a>\n",
    "        &nbsp; 642 kB (642,326 bytes)\n",
    "    </li>\n",
    "</ul>\n",
    "~~~\n",
    "\n",
    "Il link alla fine avrà la seguente struttura: *https://www.malware-traffic-analysis.net/yyyy/mm/dd/nomeRisorsa*\n",
    "<br>\n",
    "Come parser è stato scelto *lxml* per il semplice fatto che non da problemi nel caso in cui il documento non sia ben formato."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def mta_download(url, dest, log_file):\n",
    "    if not dest[-1] == '/':\n",
    "        dest += '/'\n",
    "\n",
    "        if not os.path.exists(dest):\n",
    "            os.makedirs(dest, exist_ok=True)\n",
    "\n",
    "        src = req.get(url).text\n",
    "        soup = BeautifulSoup(src, 'lxml')\n",
    "\n",
    "        name = soup.find('a', class_='menu_link')['href']\n",
    "\n",
    "        # download pcapFile\n",
    "        url_splited = url.split('/')\n",
    "        pcap_url = '/'.join(url_splited[: len(url_splited) - 1]) + f'/{name}'\n",
    "        dest_path = f'{dest + name}'\n",
    "\n",
    "        if not os.path.isfile(dest_path) or not os.path.exists(dest_path):\n",
    "            res = req.get(pcap_url)\n",
    "\n",
    "            print(pcap_url)\n",
    "            log_file.write(f'{datetime.datetime.now()} {pcap_url}\\n')\n",
    "\n",
    "            if res.status_code == 200:\n",
    "                print(LOG_SUCCESS)\n",
    "                log_file.write(f'{LOG_SUCCESS}\\n')\n",
    "                with open(dest_path, 'wb') as pcap:\n",
    "                    pcap.write(res.content)\n",
    "            else:\n",
    "                print(LOG_FAIL)\n",
    "                log_file.write(f'{LOG_FAIL}\\n')\n",
    "        else:\n",
    "            print(f\"{dest_path} - FILE GIÀ ESISTENTE\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "#TEST\n",
    "with open('download.log', 'a') as log:\n",
    "    mta_download('https://www.malware-traffic-analysis.net/2016/05/03/index.html', 'raw/pcap/test/', log)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nel caso in cui i percorso di destinazione non esiste, la funzione se lo crea automaticamente."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DOWNLOA PCAP FILES DA UNAVARRA.ES\n",
    "\n",
    "Come accennato in precedenza il download è suddiviso in 3 fasi. Nella POST va a restituire un stringa di 40 caratteri che sarà ottenuto dal valore di *sample* passato nel payload della POST.\n",
    "<br>\n",
    "*sample* conterrà il percorso del sample e ne esistono di due tipi in base allo scenario utilizzato per acquisire il traffico di rete:\n",
    "1. *Scenario* = Original -> trazasOriginal/5GBdirectory/samplesPcap_compress/*SamplePcap*;\n",
    "2. *Scenario* = NAT -> trazasNAT/samplesPcap_compress/*SamplePcap*.\n",
    "\n",
    "Uno volta ottenuta la stringa la uso per inviare una GET per ottenere la risorsa di cui sono interessato al seguete indirizzo: *http://dataset.tlm.unavarra.es/ransomware/downloads*."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#costruisce valore per attributo sample per la post\n",
    "def build_sample_attr(sample_name, scenario):\n",
    "    if scenario == \"original\":\n",
    "        return f\"trazasOriginal/5GBdirectory/{sample_name}\"\n",
    "    else:\n",
    "        return f\"trazasNAT/{sample_name}\"\n",
    "\n",
    "def ha_download(sample_name, scenario, dest, log_file):\n",
    "     if not dest[-1] == '/':\n",
    "        dest += '/'\n",
    "\n",
    "        if not os.path.exists(dest):\n",
    "            os.makedirs(dest, exist_ok=True)\n",
    "\n",
    "        url1 = \"http://dataset.tlm.unavarra.es/ransomware/php/descargar.php?\"  # usato per reperire il nome del file\n",
    "        url2 = \"http://dataset.tlm.unavarra.es/ransomware/downloads\"  # usato per scaricare il file\n",
    "        sample_value = build_sample_attr(sample_name, scenario)\n",
    "\n",
    "        payload = {'tokenDescarga': '',\n",
    "                   'descargarTodo': '0',\n",
    "                   'sample': sample_value}\n",
    "        header = {'Cookie': 'PHPSESSID=eqbdqjkqrksd7u5l585mkk71t5',\n",
    "                  'Origin': 'http://dataset.tlm.unavarra.es'}  # necessario altrimenti mi restituiva un contenuto vuoto\n",
    "\n",
    "        post_res = req.post(url1, data=payload, headers=header)\n",
    "\n",
    "        if post_res.status_code == 200:\n",
    "            if len(os.listdir(dest)) == 0:\n",
    "                post_res = post_res.json()['name'][12:]\n",
    "\n",
    "                get_res = req.get(f'{url2 + post_res}')\n",
    "\n",
    "                print(url2 + post_res)\n",
    "                log_file.write(f'{datetime.datetime.now()} {url2 + post_res}\\n')\n",
    "                log_file.write(f'\\tsample={sample_value}\\n')\n",
    "\n",
    "                if get_res.status_code == 200:\n",
    "                    print(LOG_SUCCESS)\n",
    "                    log_file.write(f'{LOG_SUCCESS}\\n')\n",
    "                    with open(f'{dest + post_res}', 'wb') as pcap:\n",
    "                        pcap.write(get_res.content)\n",
    "                else:\n",
    "                    print(LOG_FAIL)\n",
    "                    log_file.write(f'{LOG_FAIL}\\n')\n",
    "            else:\n",
    "                print('File già esistente')\n",
    "        else:\n",
    "            print(LOG_NOTEXIST)\n",
    "            log_file.write(f'{LOG_NOTEXIST}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://dataset.tlm.unavarra.es/ransomware/downloads/a67a80505872b9f61e6202aa241120650a6688d2.pcap.gz\n",
      "\tDownload successfully\n"
     ]
    }
   ],
   "source": [
    "#TEST\n",
    "with open('download.log', 'a') as log:\n",
    "    ha_download('samplesPcap_compress/cerber_10082016.pcap.gz', 'original', '/Volumes/Archivio/raw/pcap/test/', log)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nel caso in cui i percorso di destinazione non esiste, la funzione se lo crea automaticamente."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DECOMPRESSIONE ARCHIVI\n",
    "\n",
    "Per la decompressione andiamo a utilizzare il modulo **ZipFile**.\n",
    "Bisogna fare attenzione che i file con estensione *gz* non sono protetti da password, invece quelli con estensione *zip* lo sono (password: infected).\n",
    "<br>\n",
    "Per sicurezzo decidiamo di estrarre solo dile pcap nel caso in cui ci siano molteplici file con estensione diversa."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def unzip_pcap(path, type, pswd = None):\n",
    "    splitted_path = path.split('/')\n",
    "\n",
    "    dest_dir = \"/\".join(splitted_path[ : len(splitted_path) - 1])\n",
    "\n",
    "    if type == 'zip':\n",
    "        with ZipFile(path, 'r') as obj_zip:\n",
    "            for file in obj_zip.namelist():\n",
    "                if file.endswith('.pcap'): #necessaria perchè ci sono certi archivi che contengono alti file inerenti al ransonware oltre al pcap, che è ciò che mi interessa\n",
    "                    obj_zip.extract(file, f'{dest_dir}/', pwd = bytes(pswd, 'utf-8'))\n",
    "    elif type == 'gz':\n",
    "        dest_name = splitted_path[-1]\n",
    "\n",
    "        with gz.open(path, 'rb') as f_in:\n",
    "            with open(f'{dest_dir}/{dest_name[: len(archive) - 3]}', 'wb') as f_out:\n",
    "               shutil.copyfileobj(f_in, f_out)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#TEST\n",
    "for archive in os.listdir('raw/pcap/test'):\n",
    "    if not archive == \".DS_Store\":\n",
    "        print(f\"Decompressione {archive}...\")\n",
    "        if archive.endswith('zip'):\n",
    "            unzip_pcap(f'raw/pcap/test/{archive}', pswd = 'infected', type = 'zip')\n",
    "        elif archive.endswith('gz'):\n",
    "            unzip_pcap(f'raw/pcap/test/{archive}', type = 'gz')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# DOWNLOAD TRAFFICO MALEVOLO\n",
    "\n",
    "Costruite le 3 unità principale per il download (descritte sopra), andiamo a unire il tutto per ottenere l'algoritmo finale che è stato illustrato all'inizio."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: ransom_restructured.json\n"
     ]
    }
   ],
   "source": [
    "#Letture json\n",
    "ransom_samples = read_json('ransom_restructured.json')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Download file single thread"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#Download pcap files compressi\n",
    "for family in ransom_samples.keys():\n",
    "    for sample in ransom_samples[family]:\n",
    "        path = f'{DS_BASE_PCAP}/malware/{family}/{sample[\"Hash\"]}/'\n",
    "\n",
    "        if \"malware-traffic-analysis.net\" in sample[\"Link\"]:\n",
    "            with open('download.log', 'a') as log:\n",
    "                mta_download(sample[\"Link\"], path, log)\n",
    "        elif \"hybrid-analysis.com\" in sample[\"Link\"]:\n",
    "            with open('download.log', 'a') as log:\n",
    "                ha_download(sample[\"SamplePcap\"], sample[\"Scenario\"], path, log)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Download file multi thread"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Download pcap files compressi\n",
    "samples = queue.Queue()\n",
    "elems = read_json('ransom_restructured.json')\n",
    "\n",
    "for e in elems:\n",
    "    for i in range(len(elems[e])):\n",
    "        samples.put(elems[e][i])\n",
    "\n",
    "# worker lavorano fino a che non ottengono una stinga vuota\n",
    "for _ in range(NO_WORKER):\n",
    "    samples.put(\"\")\n",
    "\n",
    "# Creazione worker e li metto in coda\n",
    "workers = []\n",
    "for _ in range(NO_WORKER):\n",
    "    worker = Downloader(samples)\n",
    "    worker.start()\n",
    "    workers.append(worker)\n",
    "\n",
    "# Metto in attesa i worker fino a che non finiscono\n",
    "for worker in workers:\n",
    "    worker.join()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "L'ipotesi fatta all'inizio sul risultato della POST non si è riscontrata vera perchè nel caso in cui eseguo più POST simultanee con payload differenti (download parallelli) il risultato è sempre lo stesso nelle prime richieste perchè poi le successive non risultano problematiche perché avvengono con un cetra delta tempo l'uno dall'altra. Per risolvere tale problema, si dovrebbe mettere una sleep dopo che si è creato un nuovo thread.\n",
    "<br>\n",
    "Il dataset è stato ripulito dai file duplicati selezionando manualmente i file duplicati e riscaricandoli uno per volta."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "######################################################## DA TESTARE #########################################################\n",
    "#decompressione\n",
    "for d in os.listdir(DS_BASE_PCAP):\n",
    "    zip_path = f\"{DS_BASE_PCAP}/malware/{d}\"\n",
    "    #DA RIVEDERE PERCORSI\n",
    "    for sub_d in os.listdir(zip_path):\n",
    "        zip_path += f\"/{sub_d}\"\n",
    "\n",
    "        for archive in os.listdir(zip_path):\n",
    "                if not archive == \".DS_Store\":\n",
    "                    print(f\"Decompressione {archive}...\")\n",
    "\n",
    "                    if archive.endswith('zip'):\n",
    "                        unzip_pcap(f'{zip_path}/{archive}', pswd = 'infected', type = 'zip')\n",
    "                    elif archive.endswith('gz'):\n",
    "                        unzip_pcap(f'{zip_path}/{archive}', type = 'gz')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DOWNLOAD TRAFFICO BENEVOLO\n",
    "\n",
    "Il download del traffico benevole vengono scaricati da <a href=\"https://www.stratosphereips.org/datasets-overview\">StratosphireLab</a>."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
