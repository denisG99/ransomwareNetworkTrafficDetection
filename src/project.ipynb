{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "DATA_PATH_MALWARE = \"../csv/malware\"\n",
    "DATA_PATH_GOODWARE = \"../csv/goodware\"\n",
    "DATASET_PATH = \"../csv\"\n",
    "col_names = ['Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol', 'Timestamp',\n",
    "             'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets',\n",
    "             'Total Length of Bwd Packets', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
    "             'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean',\n",
    "             'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std',\n",
    "             'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max',\n",
    "             'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min',\n",
    "             'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length',\n",
    "             'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Min Packet Length', 'Max Packet Length',\n",
    "             'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count',\n",
    "             'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count',\n",
    "             'ECE Flag Count', 'Down/Up Ratio', 'Average Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size',\n",
    "             'Fwd Header Length_1', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate',\n",
    "             'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets',\n",
    "             'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
    "             'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward', 'Active Mean', 'Active Std',\n",
    "             'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# COSTRUZIONE DATASET\n",
    "* avendo il dataset scomposto in molteplici *csv* vado a unirli in uno singolo, almeno per un primo momento, distinguendo i files contenti traffico benevolo e malevolo;\n",
    "* rinomino i campi secondo le seguenti caratteristiche:\n",
    "    * parole separate da spazio anzichè da '_';\n",
    "    * prima lettera di ogni parola sarà maiuscola.\n",
    "* a ogni record gli accosto un codice che identifica univocamnete il Sample che ha la seguete struttura: *{G,M}\\_N*, dove:\n",
    "    * **G** ed **M** indicano rispettivamente goodware e malware;\n",
    "    * **N** indica il numero del sample preso in considerazione"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __change_name_and_order(data):\n",
    "    new_names = list()\n",
    "    #data = pd.read_csv(csv_path)\n",
    "\n",
    "    for col in data.columns:\n",
    "        new_name = col.split('_')\n",
    "        new_names.append(\" \".join(new_name).title()) #funzione title trasforma la prima lettera di ogni parola in maiuscolo (capitalizza)\n",
    "        #print(new_name)\n",
    "    data.columns = new_names\n",
    "\n",
    "    #riordinamento delle features\n",
    "    data = data.loc[:, [\"Src Ip\", \"Src Port\", \"Dst Ip\", \"Dst Port\", \"Protocol\", \"Timestamp\", \"Flow Duration\", \"Tot Fwd Pkts\",\n",
    "           \"Tot Bwd Pkts\", \"Totlen Fwd Pkts\", \"Totlen Bwd Pkts\", \"Fwd Pkt Len Max\", \"Fwd Pkt Len Min\", \"Fwd Pkt Len Mean\",\n",
    "           \"Fwd Pkt Len Std\", \"Bwd Pkt Len Max\", \"Bwd Pkt Len Min\", \"Bwd Pkt Len Mean\", \"Bwd Pkt Len Std\", \"Flow Byts S\",\n",
    "           \"Flow Pkts S\", \"Flow Iat Mean\", \"Flow Iat Std\", \"Flow Iat Max\", \"Flow Iat Min\", \"Fwd Iat Tot\", \"Fwd Iat Mean\",\n",
    "           \"Fwd Iat Std\", \"Fwd Iat Max\", \"Fwd Iat Min\", \"Bwd Iat Tot\", \"Bwd Iat Mean\", \"Bwd Iat Std\", \"Bwd Iat Max\",\n",
    "           \"Bwd Iat Min\",\"Fwd Psh Flags\", \"Bwd Psh Flags\", \"Fwd Urg Flags\", \"Bwd Urg Flags\",\n",
    "           \"Fwd Header Len\", \"Bwd Header Len\", \"Fwd Pkts S\", \"Bwd Pkts S\", \"Pkt Len Min\", \"Pkt Len Max\", \"Pkt Len Mean\",\n",
    "           \"Pkt Len Std\", \"Pkt Len Var\", \"Fin Flag Cnt\", \"Syn Flag Cnt\", \"Rst Flag Cnt\", \"Psh Flag Cnt\", \"Ack Flag Cnt\",\n",
    "           \"Urg Flag Cnt\", \"Cwe Flag Count\", \"Ece Flag Cnt\", \"Down Up Ratio\", \"Pkt Size Avg\", \"Fwd Seg Size Avg\",\n",
    "           \"Bwd Seg Size Avg\", \"Fwd Header Len\", \"Fwd Byts B Avg\", \"Fwd Pkts B Avg\", \"Fwd Blk Rate Avg\", \"Bwd Byts B Avg\",\n",
    "           \"Bwd Pkts B Avg\", \"Bwd Blk Rate Avg\", \"Subflow Fwd Pkts\", \"Subflow Fwd Byts\", \"Subflow Bwd Pkts\",\n",
    "           \"Subflow Bwd Byts\", \"Init Fwd Win Byts\", \"Init Bwd Win Byts\", \"Fwd Act Data Pkts\", \"Fwd Seg Size Min\",\n",
    "           \"Active Mean\", \"Active Std\", \"Active Max\", \"Active Min\", \"Idle Mean\", \"Idle Std\", \"Idle Max\", \"Idle Min\"]]\n",
    "\n",
    "    return data\n",
    "\n",
    "def csv_merging(dest_df, files_path):\n",
    "    id_num = 1\n",
    "\n",
    "    for csv_file in os.listdir(files_path):\n",
    "        if not (csv_file == \".DS_Store\" or \"Monday-WorkingHours\" in csv_file):\n",
    "            print(csv_file)\n",
    "            data = pd.read_csv(f\"{files_path}/{csv_file}\", encoding='utf-8', sep=',', engine='python')\n",
    "\n",
    "            data = __change_name_and_order(data)\n",
    "\n",
    "            if \"malware\" in files_path:\n",
    "                data[\"Sample ID\"] = f\"M_{id_num}\"\n",
    "            else:\n",
    "                data[\"Sample ID\"] = f\"G_{id_num}\"\n",
    "            id_num += 1\n",
    "\n",
    "            dest_df = pd.concat([dest_df, data])\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "    return dest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "csv_merging(pd.DataFrame(), DATA_PATH_MALWARE).to_csv(f\"{DATASET_PATH}/malware.csv\", index=False)\n",
    "csv_merging(pd.DataFrame(), DATA_PATH_GOODWARE).to_csv(f\"{DATASET_PATH}/goodware.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Per problemi lo script mostrato sopra per *Monday-WorkingHours.csv* non funzione quindi procedo a una procedura ad hoc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "goodware = pd.read_csv(f\"{DATASET_PATH}/goodware.csv\", low_memory=False)\n",
    "monday = pd.read_csv(f\"{DATA_PATH_GOODWARE}/Monday-WorkingHours.csv\", low_memory=False)\n",
    "\n",
    "monday[\"Sample ID\"] = \"G_51\"\n",
    "monday.columns = goodware.columns\n",
    "\n",
    "pd.concat([goodware, monday]).to_csv(f\"{DATASET_PATH}/goodware.csv\", index=False)\n",
    "\n",
    "del goodware, monday"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* eseguo labelling dei dati (MALWARE/BENIGN)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "for csv in os.listdir(DATASET_PATH):\n",
    "    if csv.endswith(\".csv\"):\n",
    "        df = pd.read_csv(f\"{DATASET_PATH}/{csv}\", low_memory=False)\n",
    "\n",
    "        if \"malware\" in csv:\n",
    "            df['Label'] = \"MALWARE\"\n",
    "        else:\n",
    "            df['Label'] = \"BENIGN\"\n",
    "\n",
    "        df.to_csv(f\"{DATASET_PATH}/{csv}\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* unisco i due dataset creati al primo punto, in un singolo dataset\n",
    "\n",
    "# NORMALIZZAZIONE DATASET\n",
    "* accstare porta e IP sorgente (analogamete per la destinarione);\n",
    "* eliminare punto da stringa che indica l'IP;\n",
    "* cambiare tipi delle features, dove necessario:\n",
    "\n",
    "Ultimi due passi sono necessari perchè algoritmi di ML accettano solo valori numerici."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def normalize_ip(csv_path):\n",
    "    data = pd.read_csv(csv_path, low_memory=False)\n",
    "\n",
    "    data.iloc[:, 0] = data.iloc[:, 0].map(lambda ip : __string_to_integer_ip(ip))\n",
    "    data.iloc[:, 2] = data.iloc[:, 2].map(lambda ip : __string_to_integer_ip(ip))\n",
    "\n",
    "    data.to_csv(csv_path, index=False)\n",
    "\n",
    "def __string_to_integer_ip(ip):\n",
    "    if not isinstance(ip, int):\n",
    "        splitted_ip = ip.split('.')\n",
    "\n",
    "        return \"\".join(splitted_ip)\n",
    "    return ip\n",
    "\n",
    "def change_features_type(csv_path, features_types):\n",
    "    data = pd.read_csv(csv_path, low_memory=False)\n",
    "\n",
    "    for i in range(data.shape[1]):\n",
    "        data.iloc[:, i].astype(features_types[i])\n",
    "\n",
    "    data.to_csv(csv_path, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Converto il formato stringa dell'indirizzo IP (aaa.bbb.ccc.ddd) in un formato comprensibile all'algoritmo di machine learning, cioè un intero nel seguente formato **aaabbbcccddd**."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "normalize_ip(f\"{DATASET_PATH}/malware.csv\")\n",
    "normalize_ip(f\"{DATASET_PATH}/goodware.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unione dataset goodware e malware in un unico file in formato csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "df_malware = pd.read_csv(f\"{DATASET_PATH}/malware.csv\", low_memory=False)\n",
    "df_goodware = pd.read_csv(f\"{DATASET_PATH}/goodware.csv\", low_memory=False)\n",
    "\n",
    "pd.concat([df_malware, df_goodware]).to_csv(f\"{DATASET_PATH}/dataset.csv\", index=False)\n",
    "\n",
    "del df_malware, df_goodware"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(f\"{DATASET_PATH}/dataset.csv\", low_memory=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convertire i timestamp in formato numerico"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unix_ts = pd.to_datetime(dataset['Timestamp']).view('int64')\n",
    "\n",
    "dataset['Timestamp'] = unix_ts\n",
    "\n",
    "del unix_ts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creare flowID (IPscr, portScr, IDdst, portDst, Protocollo)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "dataset['FlowID'] = dataset['Src Ip'].map(str) + \"_\"+ dataset['Src Port'].map(str) + \"_\" + dataset['Dst Ip'].map(str) + \"_\" + dataset['Dst Port'].map(str) + \"_\" + dataset['Protocol'].map(str)\n",
    "\n",
    "dataset.set_index('FlowID').to_csv(f\"{DATASET_PATH}/dataset.csv\", low_memory=False)\n",
    "\n",
    "del dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
